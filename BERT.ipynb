{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZFoTZ9Rd4bP"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dbamman/nlp23/blob/master/AP/BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AYm2QjD4WPA"
      },
      "source": [
        "BERT for binary or multiclass document classification using the [CLS] token as the document representation; trains a model (on `train.txt`), uses `dev.txt` for early stopping, and evaluates performance on `test.txt`.  Reports test accuracy with 95% confidence intervals.\n",
        "\n",
        "Before executing this notebook on Colab, make sure you're running on cuda (`Runtime > Change runtime type > GPU`) to make use of GPU speedups."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RXwcKMY44a04",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91c4899c-9adc-4adc-aceb-0215782c8c11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.40.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oeSgrDjF4WPC"
      },
      "outputs": [],
      "source": [
        "from transformers import BertModel, BertTokenizer\n",
        "import nltk\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import random\n",
        "from scipy.stats import norm\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F9qWkf0z4WPE"
      },
      "outputs": [],
      "source": [
        "# If you have your folder of data on your Google drive account, you can connect that here\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OcoE7WJQ6XRp"
      },
      "outputs": [],
      "source": [
        "# Change this to the directory with your data\n",
        "directory=\"/content/drive/MyDrive/ap_data/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ycKOkx34WPE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "553b626d-c192-4774-c9ce-fd2536ebc3ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Running on {}\".format(device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BuzjCRrG4WPF"
      },
      "outputs": [],
      "source": [
        "def read_labels(filename):\n",
        "    labels={}\n",
        "    with open(filename) as file:\n",
        "        for line in file:\n",
        "            cols = line.split(\"\\t\")\n",
        "            label = cols[2]\n",
        "            if label not in labels:\n",
        "                labels[label]=len(labels)\n",
        "    return labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8XetKMAw4WPF"
      },
      "outputs": [],
      "source": [
        "def read_data(filename, labels, max_data_points=1000):\n",
        "\n",
        "    data = []\n",
        "    data_labels = []\n",
        "    with open(filename) as file:\n",
        "        for line in file:\n",
        "            cols = line.split(\"\\t\")\n",
        "            label = cols[2]\n",
        "            text = cols[3]\n",
        "\n",
        "            data.append(text)\n",
        "            data_labels.append(labels[label])\n",
        "\n",
        "\n",
        "    # shuffle the data\n",
        "    tmp = list(zip(data, data_labels))\n",
        "    random.shuffle(tmp)\n",
        "    data, data_labels = zip(*tmp)\n",
        "\n",
        "    if max_data_points is None:\n",
        "        return data, data_labels\n",
        "\n",
        "    return data[:max_data_points], data_labels[:max_data_points]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZPfJqVmb4WPH"
      },
      "outputs": [],
      "source": [
        "labels=read_labels(\"%s/train.txt\" % directory)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels=read_labels('adjudicated.txt')"
      ],
      "metadata": {
        "id": "ST2ynHTdJtDV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "weLxd-8xJyh2",
        "outputId": "a7c557c6-68e6-46bc-a211-0e791bf4945f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Adolescent': 0, 'Adult': 1, 'Child': 2, 'Young Adult': 3}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total = read_data('adjudicated.txt', labels, None)"
      ],
      "metadata": {
        "id": "gA8_ZJCRKAQU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame()\n",
        "df['text'] = total[0]\n",
        "df['label'] = total[1]"
      ],
      "metadata": {
        "id": "1cE7EGxOKZ_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_x, X_temp, train_y, y_temp = train_test_split(list(df['text']), list(df['label']), test_size=0.4, random_state=42)  # 60% for training\n",
        "dev_x, test_x, dev_y, test_y = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)  # Splitting the 40% into two 20% pieces"
      ],
      "metadata": {
        "id": "6TRxHa45LC5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O-728X0b4WPI"
      },
      "outputs": [],
      "source": [
        "train_x, train_y=read_data(\"%s/train.txt\" % directory, labels, max_data_points=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zQOE469I4WPI"
      },
      "outputs": [],
      "source": [
        "dev_x, dev_y=read_data(\"%s/dev.txt\" % directory, labels, max_data_points=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vMpv6ZV54WPI"
      },
      "outputs": [],
      "source": [
        "test_x, test_y=read_data(\"%s/test.txt\" % directory, labels, max_data_points=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gUKRjWsf4WPJ"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, x, y):\n",
        "    model.eval()\n",
        "    corr = 0.\n",
        "    total = 0.\n",
        "    with torch.no_grad():\n",
        "        for x, y in zip(x, y):\n",
        "            y_preds=model.forward(x)\n",
        "            for idx, y_pred in enumerate(y_preds):\n",
        "                prediction=torch.argmax(y_pred)\n",
        "                if prediction == y[idx]:\n",
        "                    corr += 1.\n",
        "                total+=1\n",
        "    return corr/total, total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9mVrY9yv4WPL"
      },
      "outputs": [],
      "source": [
        "def confidence_intervals(accuracy, n, significance_level):\n",
        "    critical_value=(1-significance_level)/2\n",
        "    z_alpha=-1*norm.ppf(critical_value)\n",
        "    se=math.sqrt((accuracy*(1-accuracy))/n)\n",
        "    return accuracy-(se*z_alpha), accuracy+(se*z_alpha)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import BertModel, BertTokenizer, BertConfig\n",
        "import random\n",
        "\n",
        "class BERTClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, bert_model_name, params):\n",
        "        super(BERTClassifier, self).__init__()\n",
        "        self.model_name = bert_model_name\n",
        "        self.tokenizer = BertTokenizer.from_pretrained(self.model_name, do_lower_case=params.get(\"doLowerCase\", True))\n",
        "\n",
        "        # Configure BERT model with customized settings\n",
        "        self.config = BertConfig.from_pretrained(self.model_name,\n",
        "                                                 output_hidden_states=True,\n",
        "                                                 output_attentions=params.get(\"output_attentions\", False))\n",
        "        self.bert = BertModel.from_pretrained(self.model_name, config=self.config)\n",
        "\n",
        "        self.dropout = nn.Dropout(params.get(\"dropout_rate\", 0.1))\n",
        "        self.num_labels = params[\"label_length\"]\n",
        "        self.fc = nn.Linear(params[\"embedding_size\"], self.num_labels)\n",
        "\n",
        "    def get_batches(self, all_x, all_y, batch_size=32, max_toks=510):\n",
        "        # Shuffle the dataset to ensure random batch distribution\n",
        "        zipped_data = list(zip(all_x, all_y))\n",
        "        random.shuffle(zipped_data)\n",
        "        all_x, all_y = zip(*zipped_data)\n",
        "\n",
        "        batches_x, batches_y = [], []\n",
        "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "        for i in range(0, len(all_x), batch_size):\n",
        "            x = all_x[i:i+batch_size]\n",
        "            batch_x = self.tokenizer(x, padding=True, truncation=True, return_tensors=\"pt\", max_length=max_toks)\n",
        "            batch_y = all_y[i:i+batch_size]\n",
        "\n",
        "            batches_x.append(batch_x.to(device))\n",
        "            batches_y.append(torch.LongTensor(batch_y).to(device))\n",
        "\n",
        "        return batches_x, batches_y\n",
        "\n",
        "    def forward(self, batch_x):\n",
        "        bert_output = self.bert(input_ids=batch_x[\"input_ids\"],\n",
        "                                attention_mask=batch_x[\"attention_mask\"],\n",
        "                                token_type_ids=batch_x[\"token_type_ids\"])\n",
        "\n",
        "        bert_hidden_states = bert_output.hidden_states\n",
        "        out = bert_hidden_states[-1][:,0,:]\n",
        "        out = self.dropout(out)\n",
        "        out = self.fc(out)\n",
        "        return out.squeeze()\n",
        "\n",
        "def train(bert_model_name, model_filename, train_x, train_y, dev_x, dev_y, labels, embedding_size=768, doLowerCase=None, verbose=True):\n",
        "    params = {\n",
        "        \"label_length\": len(labels),\n",
        "        \"doLowerCase\": doLowerCase,\n",
        "        \"embedding_size\": embedding_size,\n",
        "        \"dropout_rate\": 0.1,\n",
        "        \"output_attentions\": False\n",
        "    }\n",
        "    bert_model = BERTClassifier(bert_model_name, params)\n",
        "    #device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    bert_model.to(device)\n",
        "\n",
        "    optimizer = torch.optim.Adam(bert_model.parameters(), lr=1e-5)\n",
        "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
        "    cross_entropy = nn.CrossEntropyLoss()\n",
        "\n",
        "    batch_x, batch_y = bert_model.get_batches(train_x, train_y)\n",
        "    dev_batch_x, dev_batch_y = bert_model.get_batches(dev_x, dev_y)\n",
        "\n",
        "    num_epochs = 30\n",
        "    best_dev_acc = 0.0\n",
        "    patience = 5\n",
        "    best_epoch = 0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        bert_model.train()\n",
        "\n",
        "        for x, y in zip(batch_x, batch_y):\n",
        "            y_pred = bert_model(x)\n",
        "            loss = cross_entropy(y_pred.view(-1, bert_model.num_labels), y.view(-1))\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "        dev_accuracy, _ = evaluate(bert_model, dev_batch_x, dev_batch_y)  # ensure evaluate function returns accuracy and loss\n",
        "        if verbose:\n",
        "            print(\"Epoch %s, dev accuracy: %.3f\" % (epoch, dev_accuracy))\n",
        "        if dev_accuracy > best_dev_acc:\n",
        "            torch.save(bert_model.state_dict(), model_filename)\n",
        "            best_dev_acc = dev_accuracy\n",
        "            best_epoch = epoch\n",
        "\n",
        "        if epoch - best_epoch > patience:\n",
        "            if verbose:\n",
        "                print(\"No improvement in dev accuracy over %s epochs; stopping training\" % patience)\n",
        "            break\n",
        "\n",
        "    bert_model.load_state_dict(torch.load(model_filename))\n",
        "    if verbose:\n",
        "        print(\"\\nBest Performing Model achieves dev accuracy of : %.3f\" % (best_dev_acc))\n",
        "    return bert_model"
      ],
      "metadata": {
        "id": "mMXF0L1jDfn-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from transformers import BertModel, BertTokenizer, BertConfig\n"
      ],
      "metadata": {
        "id": "mHX6VxArRSEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Twbsysmd4WPM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e903a96-053a-43c1-e5bd-7d143acc2f3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, dev accuracy: 0.320\n",
            "Epoch 1, dev accuracy: 0.310\n",
            "Epoch 2, dev accuracy: 0.330\n",
            "Epoch 3, dev accuracy: 0.350\n",
            "Epoch 4, dev accuracy: 0.370\n",
            "Epoch 5, dev accuracy: 0.370\n",
            "Epoch 6, dev accuracy: 0.390\n",
            "Epoch 7, dev accuracy: 0.400\n",
            "Epoch 8, dev accuracy: 0.390\n",
            "Epoch 9, dev accuracy: 0.390\n",
            "Epoch 10, dev accuracy: 0.380\n",
            "Epoch 11, dev accuracy: 0.380\n",
            "Epoch 12, dev accuracy: 0.390\n",
            "Epoch 13, dev accuracy: 0.390\n",
            "No improvement in dev accuracy over 5 epochs; stopping training\n",
            "\n",
            "Best Performing Model achieves dev accuracy of : 0.400\n"
          ]
        }
      ],
      "source": [
        "# small BERT -- can run on laptop\n",
        "bert_model_name=\"google/bert_uncased_L-2_H-128_A-2\"\n",
        "model_filename=\"mybert.model\"\n",
        "embedding_size=128\n",
        "doLowerCase=True\n",
        "\n",
        "# bert-base -- slow on laptop; better on Colab\n",
        "#bert_model_name=\"bert-base-cased\"\n",
        "#model_filename=\"mybert.model\"\n",
        "#embedding_size=768\n",
        "#doLowerCase=False\n",
        "\n",
        "model=train(bert_model_name, model_filename, train_x, train_y, dev_x, dev_y, labels, embedding_size=embedding_size, doLowerCase=doLowerCase)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UyImsx_C4WPN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77b4e34c-ff3e-493c-cbf7-21610a44fcf6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy for best dev model: 0.440, 95% CIs: [0.343 0.537]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "test_batch_x, test_batch_y = model.get_batches(test_x, test_y)\n",
        "accuracy, test_n=evaluate(model, test_batch_x, test_batch_y)\n",
        "\n",
        "lower, upper=confidence_intervals(accuracy, test_n, .95)\n",
        "print(\"Test accuracy for best dev model: %.3f, 95%% CIs: [%.3f %.3f]\\n\" % (accuracy, lower, upper))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "viXBZnpaemOa",
        "outputId": "f516ac5d-5e42-4d7f-cfad-c91a854a1e04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Adolescent': 0, 'Adult': 1, 'Child': 2, 'Young Adult': 3}"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}