{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3M-ZVl8TItsn"
      },
      "outputs": [],
      "source": [
        "from scipy import sparse\n",
        "from sklearn import linear_model\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "import operator\n",
        "import nltk\n",
        "import math\n",
        "from scipy.stats import norm\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "YhVOfrXeI-pS",
        "outputId": "2a0719b3-0ce1-4535-96f1-e7475b7570ec"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   ID  Adjudicated        Label  \\\n",
              "0   1  adjudicated   Adolescent   \n",
              "1   2  adjudicated        Adult   \n",
              "2   3  adjudicated        Child   \n",
              "3   4  adjudicated  Young Adult   \n",
              "4   5  adjudicated        Adult   \n",
              "\n",
              "                                                Text  \n",
              "0  Summary: Helen Hunt Jackson is probably most f...  \n",
              "1  Summary: Dr. Woodson describes the internal mi...  \n",
              "2  Summary: In the summer, Don and Joyce stay on ...  \n",
              "3  Summary: \"But the Knyght was a little less tha...  \n",
              "4  Summary: The young Niel Herbert idolizes Maria...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b2887934-2a00-481e-ae3b-7a68684993ba\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Adjudicated</th>\n",
              "      <th>Label</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>adjudicated</td>\n",
              "      <td>Adolescent</td>\n",
              "      <td>Summary: Helen Hunt Jackson is probably most f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>adjudicated</td>\n",
              "      <td>Adult</td>\n",
              "      <td>Summary: Dr. Woodson describes the internal mi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>adjudicated</td>\n",
              "      <td>Child</td>\n",
              "      <td>Summary: In the summer, Don and Joyce stay on ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>adjudicated</td>\n",
              "      <td>Young Adult</td>\n",
              "      <td>Summary: \"But the Knyght was a little less tha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>adjudicated</td>\n",
              "      <td>Adult</td>\n",
              "      <td>Summary: The young Niel Herbert idolizes Maria...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b2887934-2a00-481e-ae3b-7a68684993ba')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b2887934-2a00-481e-ae3b-7a68684993ba button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b2887934-2a00-481e-ae3b-7a68684993ba');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3044c0e5-b987-4218-a7a7-80a650e03230\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3044c0e5-b987-4218-a7a7-80a650e03230')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3044c0e5-b987-4218-a7a7-80a650e03230 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 500,\n  \"fields\": [\n    {\n      \"column\": \"ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 144,\n        \"min\": 1,\n        \"max\": 500,\n        \"num_unique_values\": 500,\n        \"samples\": [\n          362,\n          74,\n          375\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Adjudicated\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"adjudicated\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Adult\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 500,\n        \"samples\": [\n          \"Summary: Robert Chambers was a contemporary of Lovecraft, and this book consists of \\\"weird supernatural tales\\\" in a somewhat similar manner, except that the emphasis is on humor rather than horror. The narrator works for the newly opened Bronx Zoo in New York. He describes his adventures trying to obtain various rare specimens for the zoo's collection, animals that range from the merely extinct to the considerably more unusual. Along the way, he invariably finds a beautiful woman to fall in love with.   First: MY DEAR LE GRAND,--You and I were early drawn together by a      common love of nature. Your researches into the natural      history of the tree-toad, your observations upon the      mud-turtles of Providence Township, your experiments with the      fresh-water lobster, all stimulated my enthusiasm in a      scientific direction, which has crystallized in this helpful      little book, dedicated to you.  Random: \\\"Where the dull thunder and the tossing spray warned us from sunken  reefs, we heard the harsh challenges of gulls; where the pallid surf  twisted in yellow coils of spume above the bar, the singing sands  murmured of treachery and secrets of lost souls agasp in the throes of  silent undertows.  Last: The tremendous scientific importance of these experiences excited me  beyond measure. The simplicity of the narrative, the elaborate  attention to corroborative detail, all bore irresistible testimony to  the truth of these accounts of phenomena vitally important to the  entire world of science.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "data = pd.read_csv('adjudicated.txt', sep='\\t', header=None, names=['ID', 'Adjudicated', 'Label', 'Text'])\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G766stOII-gw"
      },
      "outputs": [],
      "source": [
        "train_data, temp_data = train_test_split(data, test_size=0.4, random_state=42)\n",
        "dev_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42)\n",
        "\n",
        "train_data.to_csv('splits/train.txt', sep='\\t', index=False, header=False)\n",
        "dev_data.to_csv('splits/dev.txt', sep='\\t', index=False, header=False)\n",
        "test_data.to_csv('splits/test.txt', sep='\\t', index=False, header=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SqrAIrcmI-P8",
        "outputId": "619a8919-d569-4b16-ef76-7194e4bda694"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "300 100 100\n"
          ]
        }
      ],
      "source": [
        "num_training_data = train_data.shape[0]\n",
        "num_dev_data = dev_data.shape[0]\n",
        "num_test_data = test_data.shape[0]\n",
        "\n",
        "print(num_training_data, num_dev_data, num_test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmN0iikPS23a",
        "outputId": "22a248fd-939e-463a-e08d-6781eee1ff95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/lib/python3.10/runpy.py:126: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
            "  warn(RuntimeWarning(msg))\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "!python -m nltk.downloader punkt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3XSrFn01TKwU"
      },
      "outputs": [],
      "source": [
        "# Replaced it with the original function in OrdianlRegression.ipynb\n",
        "def load_ordinal_data(filename, ordering):\n",
        "    X = []\n",
        "    Y = []\n",
        "    orig_Y=[]\n",
        "    for ordinal in ordering:\n",
        "        Y.append([])\n",
        "\n",
        "    with open(filename, encoding=\"utf-8\") as file:\n",
        "        for line in file:\n",
        "            cols = line.split(\"\\t\")\n",
        "            idd = cols[0]\n",
        "            label = cols[2].lstrip().rstrip()\n",
        "            text = cols[3]\n",
        "\n",
        "            X.append(text)\n",
        "\n",
        "            index=ordering.index(label)\n",
        "            for i in range(len(ordering)):\n",
        "                if index > i:\n",
        "                    Y[i].append(1)\n",
        "                else:\n",
        "                    Y[i].append(0)\n",
        "            orig_Y.append(label)\n",
        "\n",
        "    return X, Y, orig_Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t55he8-nV0ti",
        "outputId": "687d9943-fbb0-448a-cebe-1b09701c7a9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done loading data\n"
          ]
        }
      ],
      "source": [
        "# testing to see if load_original_data is correct\n",
        "ordering=[\"Child\", \"Adolescent\", \"Young Adult\", \"Adult\"]\n",
        "load_ordinal_data(\"adjudicated.txt\", ordering)\n",
        "print(\"done loading data\")\n",
        "\n",
        "#X: A list containing the texts corresponding to each data point.\n",
        "#Y: A list of lists where each inner list corresponds to the binary representation of the ordinal label for each data point. Each inner list should have a length of len(ordering) - 1, where each element indicates whether the data point belongs to a category above (1) or below (0) the corresponding category in the ordering list. For example, if the label is \"Adolescent\", the corresponding inner list would be [1, 0, 0], indicating that it's above \"Child\" but below \"Young Adult\" and \"Adult\".\n",
        "#orig_Y: A list containing the original labels for each data point."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vfyRrxuFTM93"
      },
      "outputs": [],
      "source": [
        "class OrdinalClassifier:\n",
        "\n",
        "    def __init__(self, ordinal_values, feature_method, trainX, trainY, devX, devY, testX, testY, orig_trainY, orig_devY, orig_testY):\n",
        "        self.ordinal_values=ordinal_values\n",
        "        self.feature_vocab = {}\n",
        "        self.feature_method = feature_method\n",
        "        self.min_feature_count=2\n",
        "        self.log_regs = [None]* (len(self.ordinal_values)-1)\n",
        "\n",
        "        self.trainY=trainY\n",
        "        self.devY=devY\n",
        "        self.testY=testY\n",
        "\n",
        "        self.orig_trainY=orig_trainY\n",
        "        self.orig_devY=orig_devY\n",
        "        self.orig_testY=orig_testY\n",
        "\n",
        "        self.trainX = self.process(trainX, training=True)\n",
        "        self.devX = self.process(devX, training=False)\n",
        "        self.testX = self.process(testX, training=False)\n",
        "\n",
        "    # Featurize entire dataset\n",
        "    def featurize(self, data):\n",
        "        featurized_data = []\n",
        "        for text in data:\n",
        "            feats = self.feature_method(text)\n",
        "            featurized_data.append(feats)\n",
        "        return featurized_data\n",
        "\n",
        "    # Read dataset and returned featurized representation as sparse matrix + label array\n",
        "    def process(self, X_data, training = False):\n",
        "\n",
        "        data = self.featurize(X_data)\n",
        "\n",
        "        if training:\n",
        "            fid = 0\n",
        "            feature_doc_count = Counter()\n",
        "            for feats in data:\n",
        "                for feat in feats:\n",
        "                    feature_doc_count[feat]+= 1\n",
        "\n",
        "            for feat in feature_doc_count:\n",
        "                if feature_doc_count[feat] >= self.min_feature_count:\n",
        "                    self.feature_vocab[feat] = fid\n",
        "                    fid += 1\n",
        "\n",
        "        F = len(self.feature_vocab)\n",
        "        D = len(data)\n",
        "        X = sparse.dok_matrix((D, F))\n",
        "        for idx, feats in enumerate(data):\n",
        "            for feat in feats:\n",
        "                if feat in self.feature_vocab:\n",
        "                    X[idx, self.feature_vocab[feat]] = feats[feat]\n",
        "\n",
        "        return X\n",
        "\n",
        "\n",
        "    def train(self):\n",
        "        (D,F) = self.trainX.shape\n",
        "\n",
        "\n",
        "        for idx, ordinal_value in enumerate(self.ordinal_values[:-1]):\n",
        "            best_dev_accuracy=0\n",
        "            best_model=None\n",
        "            for C in [0.1, 1, 10, 100]:\n",
        "\n",
        "                log_reg = linear_model.LogisticRegression(C = C, max_iter=1000)\n",
        "                log_reg.fit(self.trainX, self.trainY[idx])\n",
        "                development_accuracy = log_reg.score(self.devX, self.devY[idx])\n",
        "                if development_accuracy > best_dev_accuracy:\n",
        "                    best_dev_accuracy=development_accuracy\n",
        "                    best_model=log_reg\n",
        "\n",
        "\n",
        "            self.log_regs[idx]=best_model\n",
        "\n",
        "    def test(self):\n",
        "        cor=tot=0\n",
        "        counts=Counter()\n",
        "        preds=[None]*(len(self.ordinal_values)-1)\n",
        "        for idx, ordinal_value in enumerate(self.ordinal_values[:-1]):\n",
        "            preds[idx]=self.log_regs[idx].predict_proba(self.testX)[:,1]\n",
        "\n",
        "        preds=np.array(preds)\n",
        "\n",
        "        for data_point in range(len(preds[0])):\n",
        "\n",
        "\n",
        "            ordinal_preds=np.zeros(len(self.ordinal_values))\n",
        "            for ordinal in range(len(self.ordinal_values)-1):\n",
        "                if ordinal == 0:\n",
        "                    ordinal_preds[ordinal]=1-preds[ordinal][data_point]\n",
        "                else:\n",
        "                    ordinal_preds[ordinal]=preds[ordinal-1][data_point]-preds[ordinal][data_point]\n",
        "\n",
        "            ordinal_preds[len(self.ordinal_values)-1]=preds[len(preds)-1][data_point]\n",
        "\n",
        "            prediction=np.argmax(ordinal_preds)\n",
        "            counts[prediction]+=1\n",
        "            if prediction == self.ordinal_values.index(self.orig_testY[data_point]):\n",
        "                cor+=1\n",
        "            tot+=1\n",
        "\n",
        "        return cor/tot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_kgw9ACBG6RP"
      },
      "outputs": [],
      "source": [
        "def binary_bow_featurize(text):\n",
        "    feats = {}\n",
        "    words = nltk.word_tokenize(text)\n",
        "\n",
        "    for word in words:\n",
        "        word=word.lower()\n",
        "        feats[word]=1\n",
        "\n",
        "    return feats\n",
        "\n",
        "def confidence_intervals(accuracy, n, significance_level):\n",
        "    critical_value=(1-significance_level)/2\n",
        "    z_alpha=-1*norm.ppf(critical_value)\n",
        "    se=math.sqrt((accuracy*(1-accuracy))/n)\n",
        "    return accuracy-(se*z_alpha), accuracy+(se*z_alpha)\n",
        "\n",
        "def run(trainingFile, devFile, testFile, ordinal_values):\n",
        "\n",
        "    trainX, trainY, orig_trainY=load_ordinal_data(trainingFile, ordinal_values)\n",
        "    devX, devY, orig_devY=load_ordinal_data(devFile, ordinal_values)\n",
        "    testX, testY, orig_testY=load_ordinal_data(testFile, ordinal_values)\n",
        "\n",
        "    simple_classifier = OrdinalClassifier(ordinal_values, binary_bow_featurize, trainX, trainY, devX, devY, testX, testY, orig_trainY, orig_devY, orig_testY)\n",
        "    simple_classifier.train()\n",
        "    accuracy=simple_classifier.test()\n",
        "\n",
        "    lower, upper=confidence_intervals(accuracy, len(testY[0]), .95)\n",
        "    print(\"Test accuracy for best dev model: %.3f, 95%% CIs: [%.3f %.3f]\\n\" % (accuracy, lower, upper))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37D_o_lE0_lz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0617d614-698d-442e-8cbf-804659370b3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy for best dev model: 0.480, 95% CIs: [0.382 0.578]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "trainingFile = 'splits/train.txt'\n",
        "devFile = 'splits/dev.txt'\n",
        "testFile = 'splits/test.txt'\n",
        "\n",
        "run(trainingFile, devFile, testFile, ordering)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Additional Features in binary_bow_featurize"
      ],
      "metadata": {
        "id": "ifIoZsJIkuKS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7VQ1UROzLu2g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "childrens_book_words = [\n",
        "    \"Adventure\", \"Magic\", \"Fairy\", \"Princess\", \"Dragon\", \"Castle\", \"Forest\", \"Treasure\", \"Pirate\", \"Quest\",\n",
        "    \"Hero\", \"Monster\", \"Unicorn\", \"Mermaid\", \"Wizard\", \"Fairy tale\", \"Mystery\", \"Animal\", \"Friendship\", \"Brave\",\n",
        "    \"Journey\", \"Enchantment\", \"Quest\", \"Spell\", \"Fairies\", \"Prince\", \"Witch\", \"Ogre\", \"Knight\", \"Talking animals\",\n",
        "    \"Pixie\", \"Elf\", \"Adventure\", \"Enchanted\", \"Magic wand\", \"Wand\", \"Secret\", \"Mysterious\", \"Courage\", \"Mystery\",\n",
        "    \"Wondrous\", \"Happy\", \"Smile\", \"Laughter\", \"Fun\", \"Joy\", \"Playful\", \"Excitement\", \"Wonderland\", \"Dream\"\n",
        "]\n",
        "\n",
        "adult_book_words = [\n",
        "    \"Intrigue\", \"Conspiracy\", \"Betrayal\", \"Romance\", \"Drama\", \"Suspense\", \"Thriller\", \"Murder\", \"Mystery\", \"Detective\",\n",
        "    \"Investigation\", \"Crime\", \"Passion\", \"Lust\", \"Seduction\", \"Politics\", \"Power\", \"Corruption\", \"Deception\", \"Scandal\",\n",
        "    \"War\", \"Conflict\", \"Espionage\", \"Espouse\", \"Affair\", \"Affection\", \"Tension\", \"Tragedy\", \"Legacy\", \"Destiny\",\n",
        "    \"Ambition\", \"Ambiguous\", \"Temptation\", \"Devotion\", \"Obsession\", \"Revenge\", \"Manipulation\", \"Complication\", \"Betrayal\",\n",
        "    \"Sacrifice\", \"Redemption\", \"Intrigue\", \"Deceit\", \"Guilt\", \"Consequences\", \"Secret\", \"Revelation\", \"Truth\", \"Despair\", \"Hope\"\n",
        "]\n",
        "def binary_bow_featurize_additional(text):\n",
        "    feats = {}\n",
        "    words = nltk.word_tokenize(text)\n",
        "\n",
        "    for word in words:\n",
        "        word=word.lower()\n",
        "        if word in adult_book_words:\n",
        "            feats['adult_feat'] = 1\n",
        "            # feats[word] = 1\n",
        "\n",
        "        elif word in childrens_book_words:\n",
        "            feats['child_feat']=1\n",
        "            # feats[word] = 1\n",
        "        else:\n",
        "            feats[word] = 1\n",
        "    return feats\n",
        "\n",
        "\n",
        "\n",
        "def run_additional(trainingFile, devFile, testFile, ordinal_values):\n",
        "\n",
        "    trainX, trainY, orig_trainY=load_ordinal_data(trainingFile, ordinal_values)\n",
        "    devX, devY, orig_devY=load_ordinal_data(devFile, ordinal_values)\n",
        "    testX, testY, orig_testY=load_ordinal_data(testFile, ordinal_values)\n",
        "\n",
        "    simple_classifier = OrdinalClassifier(ordinal_values, binary_bow_featurize_adult, trainX, trainY, devX, devY, testX, testY, orig_trainY, orig_devY, orig_testY)\n",
        "    simple_classifier.train()\n",
        "    accuracy=simple_classifier.test()\n",
        "\n",
        "    lower, upper=confidence_intervals(accuracy, len(testY[0]), .95)\n",
        "    print(\"Test accuracy for word features model: %.3f, 95%% CIs: [%.3f %.3f]\\n\" % (accuracy, lower, upper))\n",
        "run2(trainingFile, devFile, testFile, ordering)\n"
      ],
      "metadata": {
        "id": "eMCln30bS8NN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Word Embeddings"
      ],
      "metadata": {
        "id": "JEGK_Tnrp2WE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tried another classifier that extends OrdinalClassifier class and uses vector Embeddings\n",
        "It has new featurize function called \"word_embedding_featurize\" that uses glove embeddings instead of regular word feature embeddings in our original model.\n",
        "We did the accuracy and confidence interval analysis but it turned out not to be our best performing model, but there is lot of room for improvement.\n",
        "\n",
        "imported models from https://radimrehurek.com/gensim/models/word2vec.html\n",
        "\n"
      ],
      "metadata": {
        "id": "xCCqVZn-p-Mt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sy1_JVXY-S9d",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "print(api.info())\n",
        "\n",
        "model_name = \"word2vec-google-news-300\"\n",
        "word2vec_model = api.load(model_name)\n",
        "print(\"Done laoding word2vec_model from word2vec-google-news-300 !!!!!!!!!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HoM44Yni0Cec"
      },
      "outputs": [],
      "source": [
        "from gensim.downloader import load\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "\n",
        "word2vec_model = load(\"word2vec-google-news-300\")\n",
        "\n",
        "trainX, trainY, orig_trainY=load_ordinal_data(trainingFile, ordering)\n",
        "devX, devY, orig_devY=load_ordinal_data(devFile, ordering)\n",
        "testX, testY, orig_testY=load_ordinal_data(testFile, ordering)\n",
        "\n",
        "def word_embedding_featurize(text, word_embedding_model):\n",
        "    words = nltk.word_tokenize(text.lower())\n",
        "    valid_words = [word for word in words if word not in stop_words]\n",
        "    word_embeddings = []\n",
        "    for word in valid_words:\n",
        "        if word in word_embedding_model:\n",
        "            word_embeddings.append(word_embedding_model[word])\n",
        "    if word_embeddings:\n",
        "        return np.mean(word_embeddings, axis=0)\n",
        "    else:\n",
        "        return np.zeros(word_embedding_model.vector_size)\n",
        "\n",
        "class OrdinalClassifierWithEmbeddings(OrdinalClassifier):\n",
        "\n",
        "    def __init__(self, ordinal_values, trainX, trainY, devX, devY, testX, testY, orig_trainY, orig_devY, orig_testY):\n",
        "        super().__init__(ordering, word_embedding_featurize, trainX, trainY, devX, devY, testX, testY, orig_trainY, orig_devY, orig_testY)\n",
        "\n",
        "    def featurize(self, data):\n",
        "        featurized_data = []\n",
        "        for text in data:\n",
        "            feats = self.feature_method(text, word2vec_model)\n",
        "            word_embedding_feats = word_embedding_featurize(text, word2vec_model)\n",
        "            combined_feats = np.concatenate((feats, word_embedding_feats), axis=None)\n",
        "            featurized_data.append(combined_feats)\n",
        "        return featurized_data\n",
        "\n",
        "    # Overload this function from the base class OrdinalClassifier\n",
        "    # Read dataset and returned featurized representation as sparse matrix + label array\n",
        "    def process(self, X_data, training = False):\n",
        "\n",
        "        data = self.featurize(X_data)\n",
        "#         print(data)\n",
        "\n",
        "        if training:\n",
        "            fid = 0\n",
        "            feature_doc_count = Counter()\n",
        "            for feats in data:\n",
        "                for feat in feats:\n",
        "                    feature_doc_count[feat]+= 1\n",
        "\n",
        "            for feat in feature_doc_count:\n",
        "                if feature_doc_count[feat] >= self.min_feature_count:\n",
        "                    self.feature_vocab[feat] = fid\n",
        "                    fid += 1\n",
        "\n",
        "        F = len(self.feature_vocab)\n",
        "        D = len(data)\n",
        "        X = sparse.dok_matrix((D, F))\n",
        "        for idx, feats in enumerate(data):\n",
        "            for feat in feats:\n",
        "                if feat in self.feature_vocab:\n",
        "                    X[idx, self.feature_vocab[feat]] = feats[idx]\n",
        "\n",
        "        return X\n",
        "\n",
        "\n",
        "def run_with_embeddings(trainingFile, devFile, testFile, ordinal_values):\n",
        "    ordinal_values=[\"Child\", \"Adolescent\", \"Young Adult\", \"Adult\"]\n",
        "    classifier_with_embeddings = OrdinalClassifierWithEmbeddings(ordinal_values, trainX, trainY, devX, devY, testX, testY, orig_trainY, orig_devY, orig_testY)\n",
        "    classifier_with_embeddings.train()\n",
        "    accuracy_with_embeddings = classifier_with_embeddings.test()\n",
        "    lower, upper = confidence_intervals(accuracy_with_embeddings, len(testY[0]), 0.95)\n",
        "    print(\"Test accuracy for model with word embeddings: %.3f, 95%% CIs: [%.3f %.3f]\\n\" % (accuracy_with_embeddings, lower, upper))\n",
        "\n",
        "run_with_embeddings(trainingFile, devFile, testFile, ordering)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The GloVe embedding model exhibits a similar phenomenon. It represents each word in the input text with a GloVe embedding vector, capturing the semantic meaning of words within the data context. These embedding vectors then serve as input features for the OrdinalClassifierWithEmbeddings.\n"
      ],
      "metadata": {
        "id": "A-hDgesk-hY8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Knsnax-7kk3z"
      },
      "outputs": [],
      "source": [
        "\n",
        "# trainingFile = \"/splits/train.txt\"\n",
        "# devFile = \"/splits/dev.txt\"\n",
        "# testFile = \"/splits/test.txt\"\n",
        "\n",
        "\n",
        "# run(trainingFile, devFile, testFile, ordering)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}